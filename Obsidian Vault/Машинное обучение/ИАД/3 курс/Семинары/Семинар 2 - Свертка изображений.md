## Введение
На семинаре изучаются основы компьютерного зрения с помощью нейронных сетей, фокусируясь на свертках.

**План:**
1.  Работа с изображениями в Python (NumPy, PyTorch).
2.  Применение константных сверток.
3.  Сравнение полносвязных и сверточных сетей на MNIST.

## 1. Что такое картинка
*   **Изображение как матрица пикселей:** Каждая картинка — это набор пикселей, где числовое значение пикселя отражает его яркость (от 0 до 1).
*   **Цветное изображение (RGB):** Состоит из 3 числовых матриц (красный, зеленый, синий каналы), образующих трехмерный тензор.
*   **Формат в PyTorch:** Для работы с PyTorch изображения обычно представляются в виде тензора с размерностью `(batch_size, n_channels, height, width)`.

**Пример:**
```python
from PIL import Image
import numpy as np
import torch

img = Image.open("./butterfly.jpg")
img_matrix = np.array(img) # (высота, ширина, каналы) -> (427, 640, 3)

# Преобразование для PyTorch: (batch_size, n_channels, height, width)
img_tensor = torch.tensor(img_matrix, dtype=torch.float)
img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0) # (1, 3, 427, 640)
```

## 2. Применение сверток
Свёртка – это математическая операция, которая обрабатывает изображение, чтобы выявить паттерны (границы, цвета, объекты).

### Основные слои в PyTorch
*   **`torch.nn.Conv2d`**
    *   Применяет 2D-свертку.
    *   **Параметры:**
        *   `in_channels`: количество входных каналов.
        *   `out_channels`: количество выходных каналов (число фильтров).
        *   `kernel_size`: размер ядра (фильтра) свертки (int или tuple).
        *   `stride`: шаг, на который сдвигается фильтр.
        *   `padding`: количество пикселей, добавляемых по краям изображения.
        *   `dilation`: расстояние между элементами ядра.
        *   `groups`: управляеет связями между входом и выходом.
        *   `bias`: добавлять ли обучаемое смещение.
*   **`torch.nn.MaxPool2d`**
    *   Уменьшает размерность, сохраняя наиболее "выразительные" признаки (максимумы в окне).
    *   **Параметры:** `kernel_size`, `stride`, `padding`, `dilation`.
*   **`torch.nn.Flatten`**
    *   Преобразует многомерный тензор в одномерный вектор. Полезен для перехода от сверточных слоев к полносвязным.

### Пример: Оператор Собеля для детекции границ
Оператор Собеля — "готовая" свертка для детектирования границ.

**Горизонтальные границы:**
```python
from torch.nn.functional import conv2d
sobel_hor = [[-1, -2, -1], [0, 0, 0], [1, 2, 1]]
kernel_hor = torch.tensor([[sobel_hor, sobel_hor, sobel_hor]], dtype=torch.float) # (1, 3, 3, 3)
img_conv_hor = conv2d(img_tensor, kernel_hor)
# Визуализация: plt.imshow(torch.abs(img_conv_hor[0, :, :, 0]), cmap='gray')
```

**Вертикальные границы:**
```python
sobel_ver = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]
kernel_ver = torch.tensor([[sobel_ver, sobel_ver, sobel_ver]], dtype=torch.float)
img_conv_ver = conv2d(img_tensor, kernel_ver)
# Визуализация: plt.imshow(torch.abs(img_conv_ver[0, :, :, 0]), cmap='gray')
```

**Объединенные границы:**
```python
img_conv = torch.sqrt(img_conv_ver**2 + img_conv_hor**2)
# Визуализация: plt.imshow(img_conv[0, :, :, 0], cmap='gray')
```

**Задание 1:** Свернуть изображение со случайным ядром такого же размера, как у Собеля.

## 3. Обучение полносвязной нейросети (FCN) на MNIST

**Подготовка данных:**
*   Загрузка MNIST.
*   Нормализация изображений: `T.Normalize((0.1307,), (0.3081,))`.

**Задание 2: `FcNet`**
*   **Структура:**
    *   `nn.Flatten()`: превращает 28x28 картинку в вектор 784.
    *   `nn.Linear(input_shape, hide_neurons)`: полносвязный слой.
    *   `nn.ReLU()`: функция активации.
    *   `nn.Linear(hide_neurons, hide_neurons // 2)`: полносвязный слой.
    *   `nn.ReLU()`: функция активации.
    *   `nn.Linear(hide_neurons // 2, num_classes)`: выходной слой (логиты).
	```python
class FcNet(nn.Module):
    def __init__(self, input_shape, hide_neurons=32, num_classes=10):
        super().__init__()
        self.model = nn.Sequential(
            nn.Flatten(),
            nn.Linear(input_shape, hide_neurons),
            nn.ReLU(),
            nn.Linear(hide_neurons, hide_neurons // 2),
            nn.ReLU(),
            nn.Linear(hide_neurons // 2, num_classes),
        )
    def forward(self, x):
        return self.model(x)
```

**Обучение и результаты:**
*   `model_fc = FcNet(IMG_SIZE**2).to(device)`
*   Оптимизатор: `torch.optim.SGD(model_fc.parameters(), lr=0.01)`
*   Функция потерь: `nn.CrossEntropyLoss()`
*   Обучено 25818 параметров.

**Вопрос:** Почему FCN не лучшая идея для картинок?
*   Не учитывает пространственную структуру (соседство пикселей).
*   Большое количество параметров, что ведет к переобучению и вычислительной сложности.

**Задание 3 (исправление ошибки):** `predict` функция требует `.cpu().numpy()` для переноса тензоров с GPU на CPU перед преобразованием в NumPy.

**Анализ ошибок:** Визуализация ошибочных предсказаний и матрицы ошибок (`confusion_matrix`) для выявления систематических заблуждений модели.

## 4. Обучение сверточной нейронной сети (CNN)

**Задание 3 (продолжение): `ConvNet`**
*   **Структура:**
    *   **`encoder` (извлечение признаков):**
        1.  `nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding='same')`
        2.  `nn.ReLU()`
        3.  `nn.MaxPool2d(2)` (уменьшение 28x28 -> 14x14)
        4.  `nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, padding='same')`
        5.  `nn.ReLU()`
        6.  `nn.MaxPool2d(2)` (уменьшение 14x14 -> 7x7)
        7.  `nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding='same')`
        8.  `nn.ReLU()`
        9.  `nn.MaxPool2d(2)` (уменьшение 7x7 -> 3x3. Выход: 16 каналов по 3x3)
    *   **`head` (классификатор):**
        1.  `nn.Flatten()`: превращает (B, 16, 3, 3) в (B, 144) (т.к. 16 * 3 * 3 = 144).
        2.  `nn.Linear(in_features=144, out_features=32)`
        3.  `nn.ReLU()`
        4.  `nn.Linear(in_features=32, out_features=10)` (выходной слой).

	```python
class ConvNet(nn.Module):
    def __init__(self, image_channels=1):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(in_channels=image_channels, out_channels=4, kernel_size=3, padding='same'), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, padding='same'), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding='same'), nn.ReLU(), nn.MaxPool2d(2)
        )
        self.head = nn.Sequential(
            nn.Linear(in_features=16 * 3 * 3, out_features=32), # 16 каналов * 3x3 размерность
            nn.ReLU(),
            nn.Linear(in_features=32, out_features=10)
        )
    def forward(self, x):
        out = self.encoder(x)
        out = nn.Flatten()(out)
        out = self.head(out)
        return out
    def get_embedding(self, x):
        out = self.encoder(x)
        return nn.Flatten()(out)
```

**Обучение и результаты:**
*   `model_cnn = ConvNet().to(device)`
*   Оптимизатор и функция потерь аналогичны FCN.
*   Обучено 6474 параметра.

**Вопрос:** Сравнение с FCN.
*   **Параметры:** CNN (6474) значительно меньше, чем FCN (25818).
*   **Результаты:** CNN показывает лучшие результаты (accuracy ~0.9383) по сравнению с FCN (accuracy ~0.9000). Это происходит благодаря способности сверток улавливать пространственные иерархические признаки.

## 5. Что такое эмбеддинги
*   **Определение:** Эмбеддинг (вложение) — это сопоставление произвольной сущности (текста, картинки, узла графа) некоторому вектору. Нейросеть кодирует в этом векторе полезную информацию.
*   **Получение эмбеддингов для картинок:**
    *   Обучить сложный классификатор.
    *   "Срезать" последние слои.
    *   Промежуточный слой будет выдавать вектор-эмбеддинг для каждой картинки.
*   В `ConvNet` реализован метод `get_embedding`, который возвращает выход последнего сверточного слоя после `Flatten`.

**Визуализация эмбеддингов с помощью t-SNE:**
*   `X_emb = model_cnn.get_embedding(x_batch).cpu().numpy()`
*   `TSNE(perplexity=30, random_state=42).fit_transform(X_emb)`
*   Визуализация показывает, что эмбеддинги группируются по классам, подтверждая, что модель научилась извлекать значимые признаки.

**Практическое применение:**
*   **"Туша" (backbone):** Большая нейросеть, хорошо понимающая изображения.
*   **"Голова" (head):** Небольшие модели, доучиваемые на эмбеддингах из "туши" для конкретных задач (например, классификации).
*   **"Нейросетевые фичи":** Эмбеддинги, используемые в других моделях (например, градиентный бустинг).

---