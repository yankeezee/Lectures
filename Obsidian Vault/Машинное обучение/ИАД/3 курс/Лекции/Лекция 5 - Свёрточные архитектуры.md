### **1. Batch Normalization (Пакетная нормализация)**

*   **Назначение:** Batch Normalization — это метод, который нормализует входы слоев путем корректировки и масштабирования активаций. Это помогает стабилизировать обучение и ускорить сходимость глубоких нейронных сетей, позволяя использовать более высокие темпы обучения и уменьшая чувствительность к инициализации весов.
*   **Принцип работы:** Для каждого признака (колонки) входного батча рассчитывается среднее значение и дисперсия. Затем каждый признак нормализуется (приводится к среднему 0 и дисперсии 1), а после масштабируется и сдвигается с помощью обучаемых параметров (β и γ).
    *   `x_11` ... `x_1d`
    *   `...` `...`
    *   `x_n1` ... `x_nd`
    *   `n` — размер батча (количество объектов в пакете).
    *   `d` — размерность входного вектора (количество признаков).
*   **Идея:** Приводим среднее и дисперсию каждого признака (столбца) к параметрам `β_j` и `γ_j` для `j`-го признака.

---

### **2. Layer Normalization (Послойная нормализация)**

*   **Назначение:** Layer Normalization также стабилизирует распределение активаций, но, в отличие от Batch Normalization, нормализует признаки *одного объекта* (строки) независимо от других объектов в батче. Это делает её более подходящей для рекуррентных нейронных сетей и батчей переменного размера.
*   **Принцип работы:** Нормализуется распределение «признаков» одного объекта.
    *   `n` — размер батча.
    *   `d` — размерность входного вектора.
    *   `x_ij` — `j`-й признак `i`-го объекта.
*   **Формулы:**
    *   **Среднее (`μ_i`):** Для каждого объекта `i`, среднее `μ_i` рассчитывается по всем `d` признакам:
        `μ_i = (1/d) * Σ(j=1 to d) x_ij`
    *   **Дисперсия (`σ_i^2`):** Для каждого объекта `i`, дисперсия `σ_i^2` рассчитывается по всем `d` признакам:
        `σ_i^2 = (1/d) * Σ(j=1 to d) (x_ij - μ_i)^2`
    *   **Масштабирование выходов:** Нормализованные выходы `x_hat_ij` получаются:
        `x_hat_ij = (x_ij - μ_i) / √(σ_i^2 + ε)` (где `ε` — маленькое число для стабильности).
    *   **Сдвиг и масштабирование:** Затем применяются обучаемые параметры `γ` и `β` (скаляры), чтобы вернуть сети способность к нелинейным преобразованиям:
        `z_ij = γ * x_hat_ij + β`
*   **Источник:** Подробнее можно прочитать в статье "Layer Normalization" (arxiv.org/pdf/1607.06450.pdf).

---

### **3. Инициализация весов**

*   **Проблема симметрии:** Нельзя инициализировать все веса одним и тем же числом (например, нулями), так как это приведет к симметрии, при которой все нейроны в слое будут обучаться одинаково, что не позволит сети учиться сложным паттернам.
*   **Хороший вариант:** Для инициализации весов `w_j` предлагается использовать нормальное распределение с нулевым средним и дисперсией, зависящей от числа входов `n`:
    `w_j ~ N(0, 2/√n)`
    *   `n` — число входов нейрона.
*   **Цель:** Сделать так, чтобы масштаб всех выходов был примерно одинаковым, предотвращая проблемы затухающих или взрывающихся градиентов.
*   **Источник:** Статья на pouannes.github.io/blog/initialization/

---

### **4. Аугментация данных (Data Augmentation)**

*   **Что это:** Аугментация данных — это техники, которые используются для увеличения разнообразия обучающего набора данных путем создания модифицированных версий изображений из существующего набора.
*   **Примеры (визуальные):**
    *   Базовое изображение (например, тюльпаны).
    *   Множество вариаций одного изображения (например, различные обрезки, повороты).
    *   Цветовые преобразования (например, инверсия цветов).
    *   Сложные аугментации (RGBShift, HueSaturationValue, ChannelShuffle, CLAHE, RandomContrast, RandomGamma, RandomBrightness, Blur, MedianBlur, ToGray, JpegCompression).
*   **Преимущества:**
    *   **Множество разных вариантов:** Позволяет создавать большое количество новых обучающих примеров.
    *   **«Бесплатное» расширение обучающей выборки:** Увеличивает размер датасета без необходимости собирать новые данные вручную.
    *   **Регуляризация модели:** В некотором смысле, действует как регуляризация, помогая модели стать более устойчивой к небольшим изменениям во входных данных и улучшая её обобщающую способность.
*   **Практика:**
    *   Обычно аугментации случайно применяют к картинкам из текущего батча во время обучения.
    *   На этапе применения (инференса) можно сделать несколько аугментаций одного изображения, пропустить каждую через сеть и усреднить предсказания, что может улучшить стабильность и точность.
*   **Источники:** TensorFlow tutorials (www.tensorflow.org/tutorials/images/data_augmentation), Albumentations (github.com/albumentations-team/albumentations).

---

### **5. Архитектуры свёрточных сетей**

#### **5.1. LeNet (1998)**

*   **Описание:** Одна из первых успешных свёрточных нейронных сетей, разработанная Яном ЛеКуном для распознавания рукописных цифр.
*   **Архитектура (упрощенно):**
    *   Вход: 32x32 изображение.
    *   Слой C1: 6 свёрточных карт 28x28.
    *   Слой S2: 6 карт 14x14 (субдискретизация).
    *   Слой C3: 16 карт 10x10.
    *   Слой S4: 16 карт 5x5 (субдискретизация).
    *   Слой C5: полносвязный слой с 120 нейронами.
    *   Слой F6: полносвязный слой с 84 нейронами.
    *   Выход: 10 нейронов (для 10 классов цифр).
*   **Ключевые особенности:**
    *   Разработана для данных MNIST.
    *   Идея сквозного (end-to-end) обучения.
    *   Использовали аугментацию данных.
    *   Около 60 000 параметров.
    *   Доля ошибок на тесте: 0.8%.
*   **Источник:** "Gradient-based learning applied to document recognition" (yann.lecun.com/exdb/publis/pdf/lecun-98.pdf).

#### **5.2. ImageNet Large Scale Visual Recognition Challenge (ILSVRC)**

*   **Значение:** ILSVRC был ежегодным соревнованием по классификации и обнаружению объектов на изображениях, которое значительно стимулировало развитие глубокого обучения.
*   **Данные:** Использовалась база данных ImageNet, содержащая:
    *   Около 1 000 000 изображений.
    *   1000 классов объектов.
*   **Метрика качества:** Обычно качество измерялось на основе лучшей гипотезы модели (top-1 или top-5 ошибка).
*   **Источник:** image-net.org/challenges/LSVRC/

#### **5.3. AlexNet (2012)**

*   **Значение:** Победитель ILSVRC 2012, значительно превзошел классические методы и положил начало эре глубокого обучения в компьютерном зрении.
*   **Авторы:** Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton (Университет Торонто).
*   **Архитектура:** Значительно глубже LeNet, включает 5 свёрточных слоев и 3 полносвязных слоя. Использовались перекрывающиеся пулинги.
*   **Ключевые особенности:**
    *   Использование функций активации ReLU (Rectified Linear Unit), которая помогла решить проблему затухающих градиентов.
    *   Аугментация данных.
    *   Dropout для борьбы с переобучением.
    *   Градиентный спуск с инерцией (momentum) для оптимизации.
    *   Обучение на двух GPU (для распределения по памяти и ускорения) занимало 5-6 суток.
    *   Около 60 миллионов параметров.
    *   Ошибка на ImageNet: около 17%.
*   **Источник:** "ImageNet Classification with Deep Convolutional Neural Networks" (papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf).

#### **5.4. VGG (2014)**

*   **Значение:** Модель, показавшая, что глубина сети является критически важным компонентом для хорошей производительности.
*   **Авторы:** Karen Simonyan & Andrew Zisserman (Visual Geometry Group, Оксфордский университет).
*   **Ключевая идея:** Использование *только маленьких свёрток* (3x3). Вместо больших свёрток (например, 5x5 или 7x7) VGG использует стеки из нескольких 3x3 свёрток. Например, две 3x3 свёртки имеют такой же эффективный рецептивный полем, как одна 5x5, но с меньшим числом параметров и большим количеством нелинейностей (из-за дополнительных функций активации).
*   **Архитектура:** Представлено несколько конфигураций (A, A-LRN, B, C, D, E) с разной глубиной (от 11 до 19 слоев). Все они состоят из стеков 3x3 свёрточных слоев, за которыми следуют слои макс-пулинга, и заканчиваются тремя полносвязными слоями (FC-4096, FC-4096, FC-1000) и Softmax.
*   **Преимущества маленьких свёрток:**
    *   Меньше параметров.
    *   Больше нелинейностей (т.к. больше свёрточных слоев).
    *   Большее число параметров в свёрточных слоях по сравнению с полносвязными (для VGG).
*   **Тренировка:**
    *   Градиентный спуск с инерцией (SGD with momentum).
    *   Dropout для двух первых полносвязных слоев.
    *   **Хитрая инициализация:** Сначала обучался "легкий" вариант (А) со случайными весами. Затем веса обученной модели А использовались для инициализации более глубоких сетей, что помогало в их обучении.
*   **Число параметров:** Варьируется от 133 миллионов (A, A-LRN, B) до 144 миллионов (E).
*   **Производительность (на ILSVRC 2012):** Конфигурация E достигла top-1 ошибки 25.5% и top-5 ошибки 8.0%.
*   **Источник:** "Very Deep Convolutional Networks for Large-Scale Image Recognition" (arxiv.org/pdf/1409.1556.pdf).

#### **5.5. GoogLeNet (Inception v1) (2014)**

*   **Значение:** Победитель ILSVRC 2014. Ввел концепцию "Inception модуля", который позволял сети самой выбирать оптимальный размер фильтра для слоя.
*   **Авторы:** Christian Szegedy et al. (Google Inc.).
*   **Ключевая идея: Inception Module (модуль «начало»):**
    *   Вместо выбора одного типа свёртки (например, только 3x3), Inception модуль выполняет несколько операций параллельно: 1x1 свёртка, 3x3 свёртка, 5x5 свёртка и 3x3 макс-пулинг.
    *   Выходы всех этих операций конкатенируются (объединяются по канальному измерению).
    *   **"Projection layer" (проекционный слой) / 1x1 свёртка:** Очень важна для уменьшения размерности (числа каналов) *перед* "тяжелыми" (3x3, 5x5) свёртками. Это позволяет значительно сократить вычислительную сложность и количество параметров, сохраняя при этом выразительность.
    *   Свёртки делаются с паддингом для сохранения пространственного размера.
*   **Особенности:**
    *   Снижается число каналов перед «тяжёлыми» свёртками.
    *   Несколько выходных слоев (auxiliary classifiers) для улучшения обучаемости и борьбы с затухающими градиентами в глубоких сетях.
    *   Обучается градиентным спуском с инерцией.
    *   Ошибка на ImageNet: 6.67%.
*   **Источник:** "Going Deeper with Convolutions" (arxiv.org/abs/1409.4842).

#### **5.6. ResNet (Residual Network) (2015)**

*   **Значение:** Победитель ILSVRC 2015. Ввел концепцию остаточных связей (residual connections), которая позволила обучать очень глубокие сети (сотни слоев) без деградации производительности.
*   **Авторы:** Kaiming He et al. (Microsoft Research).
*   **Проблема глубоких сетей:** Добавление слоев в "plain" свёрточную сеть *ухудшает качество даже на обучении*. Это не переобучение, а "проблема деградации", когда глубокой сети становится сложнее аппроксимировать тождественное отображение, чем более мелкой. Хотя возможностей для переобучения больше, сеть почему-то не может ими воспользоваться.
*   **Решение: Residual Block (Остаточный блок):**
    *   Вместо того, чтобы слой пытался напрямую выучить отображение `H(x)`, он учится "остатку" `F(x) = H(x) - x`. Тогда желаемое отображение становится `F(x) + x`.
    *   Прямой путь `x` (skip connection/identity mapping) добавляется к выходу блока свёрток `F(x)`. Это значительно упрощает обучение тождественному отображению (`F(x)` просто нужно стать нулем).
    *   Пример блока: `x` -> `weight layer` -> `relu` -> `weight layer` -> `+x` -> `relu`.
*   **Архитектура:** Строится из множества таких остаточных блоков. Сравниваются "plain" сети и "residual" сети (например, 34-слойные).
*   **Global Average Pooling (Глобальное среднее пулинг):** Вместо использования полносвязных слоев в конце сети, ResNet часто использует Global Average Pooling. Этот слой усредняет активации каждого канала по всей пространственной размерности, что дает один скаляр на каждый канал.
    *   **Преимущество:** Позволяет работать с изображениями разного размера, так как выход Global Average Pooling всегда имеет фиксированную размерность (равную числу каналов), независимо от входного пространственного размера.
*   **Особенности:**
    *   Даёт низкую ошибку на обучении даже с 1000 слоев (но там плохо на тестовой выборке).
    *   Обучается градиентным спуском с инерцией со случайной инициализацией.
    *   Ошибка на ImageNet: 4.49%.
*   **Источник:** "Deep Residual Learning for Image Recognition" (arxiv.org/abs/1512.03385).

#### **5.7. Эволюция архитектур**

*   Наглядный график показывает снижение top-5 ошибки на ILSVRC с течением времени:
    *   ILSVRC'10 (Shallow) ~28.2%
    *   ILSVRC'11 ~25.8%
    *   ILSVRC'12 (AlexNet, 8 слоев) ~16.4%
    *   ILSVRC'13 (ZFNet, 8 слоев) ~11.7%
    *   ILSVRC'14 (VGG, 19 слоев) ~7.3%
    *   ILSVRC'14 (GoogLeNet, 22 слоя) ~6.7%
    *   ILSVRC'15 (ResNet, 152 слоя) ~3.57%

#### **5.8. Xception (2016)**

*   **Значение:** Расширение Inception архитектуры, основанное на идее "глубоко-разделимых свёрток" (depthwise separable convolutions).
*   **Ключевая идея:**
    *   Разделяется роль свёрток: либо по каналам (1x1 свёртка), либо по пространству (пространственная свёртка применяется независимо к каждому каналу).
    *   Это концепция "Extreme Inception", где 1x1 свёртка сначала проецирует входные каналы на новое пространство, а затем пространственные свёртки применяются независимо к каждому из этих новых каналов, после чего результаты конкатенируются.
*   **Преимущества:** Более эффективное использование параметров при сохранении или улучшении производительности.
*   **Источник:** "Xception: Deep Learning with Depthwise Separable Convolutions" (arxiv.org/abs/1610.02357).

#### **5.9. Что ещё? (Другие архитектуры)**

*   **Highway networks:** Вводят gating-механизм для регулирования потока информации, подобно LSTM, для обучения очень глубоких сетей.
*   **Inception-ResNet:** Комбинирует идеи Inception модулей и остаточных связей.
*   **Squeeze and Excitation Network:** Вводят механизм внимания к каналам, который позволяет сети динамически выделять более важные каналы.
*   **MobileNet:** Разработаны для мобильных и встраиваемых устройств, используют depthwise separable convolutions для снижения вычислительной стоимости и количества параметров.
*   **EfficientNet:** Используют составное масштабирование (compound scaling) для одновременной оптимизации глубины, ширины и разрешения сети.

---

### **6. Transfer Learning (Перенос знаний)**

*   **Что это:** Использование модели, уже обученной на одной задаче (обычно на большом датасете, таком как ImageNet), в качестве отправной точки для новой, связанной задачи.
*   **Мотивация:**
    *   ImageNet содержит огромное количество данных, которые сложно собрать.
    *   Годы улучшений в архитектурах и алгоритмах обучения.
    *   Нет необходимости повторять этот трудоёмкий процесс для каждой новой задачи с нуля.
*   **Стратегии дообучения (Fine-tuning):**
    *   **Если данных совсем мало:**
        *   Берём модель, обученную на другой задаче (например, ImageNet).
        *   Заменяем последний полносвязный слой (классификатор) на новый слой с нужным числом выходов, соответствующим новой задаче.
        *   Обучаем *только этот новый* последний слой. По сути, это обучение линейной модели на основе высокоуровневых признаков, извлеченных предобученной частью сети.
    *   **Если данных не очень мало:**
        *   Берём предобученную модель.
        *   Заменяем последний слой.
        *   Обучаем его *и несколько слоев до него*.
        *   Чем ближе к началу слой, тем ниже (меньше) стоит делать градиентный шаг (т.е. использовать меньший learning rate), чтобы не "испортить" хорошо изученные общие признаки.
*   **Общие принципы:**
    *   Как правило, на первых слоях фильтры находят общие, низкоуровневые признаки (края, текстуры), которые похожи для всех задач компьютерного зрения.
    *   Чем сильнее новая задача отличается от исходной (на которой обучалась модель), тем больше слоев нужно "переучивать" или "дообучать".
    *   В любом случае, выходы последних слоев модели, обученной на ImageNet, как правило, являются лучшими признаками по сравнению со случайно инициализированными.
*   **Источник:** "How transferable are features in deep neural networks?" (arxiv.org/abs/1411.1792).

---

### **7. Интерпретация моделей (Что находят свёрточные сети?)**

*   **Цель:** Понять, какие паттерны или признаки активируют конкретные фильтры в разных слоях свёрточной сети.
*   **Метод:** Для каждого фильтра можно найти кусочки картинок (патчи), которые дают самый сильный отклик (максимально активируют этот фильтр).
*   **Пример для AlexNet:**
    *   **Слой 1:** Находит простые признаки, такие как ориентированные края и цветовые пятна.
    *   **Слой 2:** Обнаруживает более сложные текстурные паттерны (решётки, круги, полосы).
    *   **Слой 3:** Начинает обнаруживать части объектов и более сложные формы (колеса, элементы одежды, лица).
    *   **Слой 4:** Обнаруживает части объектов, более специфичные для классов (например, головы собак, формы машин).
    *   **Слой 5:** Находит целые объекты или их характерные части, которые сильно коррелируют с определёнными классами (например, собаки, здания, лодки).
*   **Источник:** "Visualizing and Understanding Convolutional Networks" (cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf).

---

### **8. Максимизация вероятности класса (Глубокие сны / Inceptionism)**

*   **Цель:** Сгенерировать изображение, которое максимально активирует определённый класс или фильтр в нейронной сети.
*   **Метод:**
    *   Инициализируем картинку случайным шумом (или существующим изображением).
    *   Используем градиентный спуск (точнее, градиентный подъём) для изменения пикселей изображения таким образом, чтобы максимизировать значение функции активации для желаемого класса `a_y(x)` при условии регуляризации `λ||x||^2` (чтобы изображение не выглядело слишком шумно).
    *   `a_y(x) - λ||x||^2 -> max_x`
    *   Мы ищем оптимальную для данного класса картинку градиентным спуском.
*   **Результаты (визуальные):**
    *   **Генерация объектов:** Изображения, максимально похожие на заданный класс (гантели, чашки, далматинцы, перец, лимоны, хаски, рыба-анемон, бананы, парашюты, винты).
    *   **DeepDream / Inceptionism:** Когда процесс применяется рекурсивно на разных уровнях сети, это приводит к сюрреалистическим, "сновидческим" изображениям, где сеть "видит" и усиливает известные ей паттерны. Например, из обычной фотографии пейзажа могут быть созданы изображения, где деревья превращаются в пагоды, листья в птиц или насекомых, а облака — в элементы архитектуры.
*   **Источник:** Google Research Blog "Inceptionism: Going Deeper into Neural Networks" (research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html).

---