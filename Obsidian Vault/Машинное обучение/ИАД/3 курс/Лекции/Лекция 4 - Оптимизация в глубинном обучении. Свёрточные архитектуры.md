
### Модификации градиентного спуска

#### Проблемы градиентного спуска
Стандартный градиентный спуск имеет ряд проблем:
*   **"Вытянутые" линии уровня:** Если функция имеет сильно "вытянутые" линии уровня (например, эллиптические), градиентный спуск требует очень аккуратного выбора длины шага.
*   **Медленная сходимость:** В таких случаях градиентный спуск будет сходиться очень долго, поскольку он колеблется вдоль узких "долин" функции потерь.

#### Momentum (Инерция)
Метод Momentum ускоряет градиентный спуск в релевантных направлениях и снижает колебания.
*   **Идея:** Добавить "инерцию" к движению по градиенту, как будто шарик катится по поверхности.
*   **$h_t$** — "инерция", усреднённое направление движения.
*   **$\alpha$** — параметр затухания, определяющий, насколько сильно предыдущая инерция влияет на текущее движение.
*   **Формулы обновления:**
    *   $h_t = \alpha h_{t-1} + \eta \nabla Q(w^{t-1})$
    *   $w^t = w^{t-1} - h_t$
*   Momentum помогает модели двигаться более стабильно к минимуму, преодолевая мелкие локальные оптимумы и избегая колебаний.

#### Nesterov Momentum (Nesterov Accelerated Gradient - NAG)
Nesterov Momentum представляет собой модификацию Momentum, которая "заглядывает вперёд", вычисляя градиент в точке, куда предположительно переместится вес с учётом инерции.
*   **Идея:** Вместо вычисления градиента в текущей точке $w^{t-1}$, градиент вычисляется в точке $w^{t-1} - \alpha h_{t-1}$, которая является "неплохой оценкой того, куда мы попадём на следующем шаге".
*   **Формулы обновления:**
    *   $h_t = \alpha h_{t-1} + \eta \nabla Q(w^{t-1} - \alpha h_{t-1})$
    *   $w^t = w^{t-1} - h_t$
*   Этот подход часто приводит к более быстрой сходимости, чем обычный Momentum.

#### Проблемы с разреженными данными
*   **Пример:** Модель, использующая категориальные признаки с one-hot кодированием.
*   **Суть проблемы:** Некоторые категории (популярные) будут обновлять свои веса часто, а редкие категории — очень редко. Это приводит к тому, что по разным параметрам мы движемся с разной скоростью.
*   **Решение:** Желательно учитывать это, чтобы параметры обучались с разным качеством и скоростью, а не с фиксированной.

#### Проблема с разными масштабами
*   **Суть проблемы:** Если признаки имеют сильно разный масштаб (от единиц до миллионов), то использование единой длины шага для всех параметров неэффективно.
*   **Решение:** Необходимо адаптировать скорость обучения для каждого параметра индивидуально.

#### AdaGrad (Adaptive Gradient)
AdaGrad — это адаптивный алгоритм скорости обучения, который масштабирует скорость обучения для каждого параметра индивидуально на основе их прошлых градиентов.
*   **Идея:** Для каждого параметра поддерживается своя скорость обучения, которая уменьшается для часто обновляемых параметров и остаётся относительно высокой для редко обновляемых.
*   **Формулы обновления:**
    *   Накопление квадратов градиентов: $G_j^t = G_j^{t-1} + (\nabla Q(w^{t-1}))_j^2$
    *   Обновление веса: $w_j^t = w_j^{t-1} - \frac{\eta_t}{\sqrt{G_j^t + \epsilon}} (\nabla Q(w^{t-1}))_j$
    *   Где $\eta_t$ — общая скорость обучения, $G_j^t$ — сумма квадратов градиентов для $j$-го параметра до шага $t$, $\epsilon$ — маленькое число для стабильности (предотвращение деления на ноль).
*   **Недостаток:** Длина шага может убывать слишком быстро и привести к ранней остановке обучения (стагнации).

#### RMSProp (Root Mean Square Propagation)
RMSProp — это алгоритм, который решает проблему быстрого затухания скорости обучения в AdaGrad, используя скользящее среднее для квадратов градиентов.
*   **Идея:** Вместо накопления всех прошлых квадратов градиентов, RMSProp использует экспоненциально взвешенное скользящее среднее, что позволяет сосредоточиться на более недавних градиентах.
*   **Формулы обновления:**
    *   Скользящее среднее квадратов градиентов: $G_j^t = \alpha G_j^{t-1} + (1 - \alpha)(\nabla Q(w^{t-1}))_j^2$
    *   Обновление веса: $w_j^t = w_j^{t-1} - \frac{\eta_t}{\sqrt{G_j^t + \epsilon}} g_{tj}$ (где $g_{tj}$ — $j$-я компонента градиента на шаге $t$)
*   **Параметр $\alpha$:** Обычно $\alpha \approx 0.9$.
*   **Преимущество:** Скорость обучения зависит только от недавних шагов, что предотвращает слишком быстрое уменьшение длины шага.

#### Adam (Adaptive Moment Estimation)
Adam — это один из наиболее популярных и эффективных адаптивных алгоритмов оптимизации, который комбинирует идеи Momentum и RMSProp.
*   **Идея:** Поддерживает как экспоненциально взвешенное скользящее среднее градиентов (как Momentum, так называемый "первый момент" $m_j^t$), так и экспоненциально взвешенное скользящее среднее квадратов градиентов (как RMSProp, так называемый "второй момент" $v_j^t$).
*   **Формулы обновления:**
    *   **Первый момент (оценка среднего градиента):** $m_j^t = \frac{\beta_1 m_j^{t-1} + (1 - \beta_1)(\nabla Q(w^{t-1}))_j}{1 - \beta_1^t}$
    *   **Второй момент (оценка нецентрированной дисперсии градиента):** $v_j^t = \frac{\beta_2 v_j^{t-1} + (1 - \beta_2)(\nabla Q(w^{t-1}))_j^2}{1 - \beta_2^t}$
    *   **Обновление веса:** $w_j^t = w_j^{t-1} - \frac{\eta_t}{\sqrt{v_j^t + \epsilon}} m_j^t$
*   **Рекомендованные гиперпараметры:** $\beta_1 = 0.9$, $\beta_2 = 0.999$, $\epsilon = 10^{-8}$.
*   **Преимущества:** Сочетает преимущества Momentum (быстрая сходимость) и AdaGrad/RMSProp (адаптивная скорость обучения для каждого параметра), что делает его очень надёжным и широко используемым.

---

### Dropout
Dropout — это метод регуляризации, используемый для борьбы с переобучением в нейронных сетях.

#### Борьба с переобучением
*   **Сокращение числа параметров:** Свёрточные слои могут помочь в этом.
*   **Регуляризация:** Введение штрафов в функцию потерь.
*   **Мешать модели подгоняться под обучающую выборку:** Dropout относится к этой категории.

#### Принцип Dropout
*   Во время обучения случайным образом "выбрасываются" (обнуляются активации) некоторые нейроны из слоя с определённой вероятностью $p$.
*   Это означает, что они временно не участвуют ни в прямом, ни в обратном распространении.
*   **Интерпретация:** Dropout можно рассматривать как обучение ансамбля из огромного числа "тонких" нейросетей, где каждая подсеть использует общий набор весов исходной сети, но с разными случайно удалёнными нейронами. На этапе применения (инференса) прогнозы всех этих архитектур (почти) усредняются.

#### Dropout как слой
*   Dropout может быть определён как отдельный слой $d(x)$.
*   **Параметров нет:** Единственный гиперпараметр — $p$ (вероятность удаления нейрона).
*   **На этапе обучения:**
    *   $d(x) = \frac{1}{1-p} m \circ x$
    *   Где $m$ — вектор того же размера, что и $x$, элементы которого берутся из распределения Бернулли $Ber(p)$ (т.е., $m_i = 0$ с вероятностью $p$, и $m_i = 1$ с вероятностью $1-p$). Операция $\circ$ обозначает поэлементное умножение (произведение Адамара).
    *   **Деление на $1-p$:** Это масштабирование необходимо для сохранения суммарного масштаба выходов. Если $1-p$ нейронов остаются активными, их суммарный вклад уменьшится. Деление на $1-p$ компенсирует это снижение, гарантируя, что ожидаемое значение выхода нейрона остаётся тем же, что и без dropout.
*   **На этапе применения (инференса):**
    *   $d(x) = x$
    *   На этом этапе все нейроны активны, и их веса не масштабируются. (Этот вариант известен как "inverted dropout", он более распространён, поскольку требует меньше операций во время применения сети).
*   **Оригинальная статья:** В оригинальной статье нормировка $1/(1-p)$ отсутствовала на этапе обучения, но вместо этого использовалось домножение на $(1-p)$ на этапе применения.

---

### Нормализации

#### Covariate Shift
*   **Определение:** В классическом машинном обучении covariate shift означает изменение распределения входных данных между обучающей и тестовой выборками.
*   **Domain adaptation:** Идея состоит в том, чтобы взвешивать объекты при обучении, чтобы они соответствовали распределению тестовых данных.
    *   $\sum_{i=1}^{\ell} s_i(a(x_i) - y_i)^2 \to \min$
    *   Большие веса $s_i$ присваиваются объектам, которые похожи на объекты из тестовой выборки.

#### Internal Covariate Shift
*   **Определение:** В контексте нейронных сетей каждый слой обучается на выходах предыдущих слоёв. Если распределение выходов предыдущего слоя сильно меняется в процессе обучения, то все последующие слои вынуждены постоянно "подстраиваться" под новое распределение, что замедляет и усложняет обучение.
*   **Идея решения:** Преобразовывать выходы слоёв так, чтобы они гарантированно имели фиксированное распределение.

#### Batch Normalization (Пакетная нормализация)
Batch Normalization — это метод, который нормализует входы слоёв нейронной сети, чтобы они имели фиксированное среднее и дисперсию, тем самым уменьшая internal covariate shift.
*   **Реализация:** Как отдельный слой.
*   **Вычисления:** Вычисляется для текущего батча данных.
*   **Оценка среднего и дисперсии для каждой компоненты входного вектора $x_{B,j}$ (для $j$-й компоненты в батче $B$):**
    *   Среднее по батчу: $\mu_B = \frac{1}{n} \sum_{j=1}^n x_{B,j}$
    *   Дисперсия по батчу: $\sigma_B^2 = \frac{1}{n} \sum_{j=1}^n (x_{B,j} - \mu_B)^2$
    *   Где $n$ — размер батча, а $d$ — размерность входного вектора (нормализация происходит покоординатно для каждой из $d$ компонент).
*   **Нормализация и масштабирование:**
    *   **Отмасштабированные выходы (нормализация до нулевого среднего и единичной дисперсии):** $\tilde{x}_{B,j} = \frac{x_{B,j} - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}$
    *   **Задание нужного среднего и дисперсии (обучаемые параметры):** $z_{B,j} = \gamma \circ \tilde{x}_{B,j} + \beta$
        *   Где $\gamma$ и $\beta$ — обучаемые параметры (векторы, размерность которых равна размерности входных векторов). Они позволяют сети сохранить выразительную способность и научиться оптимально масштабировать и смещать нормализованные активации.
*   **Важно:** После BatchNorm среднее и дисперсия каждого выхода зависят только от параметров нормализации ($\gamma, \beta$), но не от параметров прошлых слоёв!
*   **Во время применения нейронной сети (инференса):** Вместо $\mu_B$ и $\sigma_B^2$, вычисленных по текущему батчу, используются их средние значения, накопленные за время обучения по всем батчам (бегущее среднее и дисперсия).
*   **Преимущества:**
    *   Обычно вставляется между полносвязным/свёрточным слоём и функцией нелинейности.
    *   Позволяет увеличить длину шага в градиентном спуске, что ускоряет обучение.
    *   Делает сеть менее чувствительной к инициализации весов.

#### В чём польза от BatchNorm?
Исследования, такие как "How Does Batch Normalization Help Optimization?", показывают, что Batch Normalization не обязательно напрямую устраняет internal covariate shift, но имеет другие важные оптимизационные преимущества:
*   **Повышенная устойчивость к шуму:** Добавление шума после нормализации не ухудшает качество обучения.
*   **Более "гладкий" функционал ошибки:** Batch Normalization делает ландшафт функции потерь более гладким и хорошо обусловленным, что облегчает работу оптимизаторов и позволяет использовать бóльшие скорости обучения.
*   **Улучшение связи градиентов:** Уменьшается зависимость градиентов от параметров предыдущих слоёв, что стабилизирует обучение.

---
### Цитированные источники:
*   Слайд 5
*   Слайды 8, 9
*   Слайд 9
*   https://jmlr.org/papers/v15/srivastava14a.html (Слайд 24)
*   https://arxiv.org/pdf/1502.03167.pdf (Слайд 36)
*   https://arxiv.org/pdf/1805.11604.pdf (Слайд 43)
*   Слайд 44
*   Слайд 46
*   Слайд 45