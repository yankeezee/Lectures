---
date: 
tags: 
authors: К.В.Воронцов

Abstract:  
---
### Математические основы машинного обучения
[PDF](zotero://select/library/items/BHYQ63Y9)

### Notes

# 1 Введение: задачи обучения по прецедентам
([4](zotero://open-pdf/library/items/BHYQ63Y9?page=4&annotation=WAT8QFH9))
<div class="custom-comment" style="border-left: 4px solid #ff0000; background-color: #fff0f0;">
  <p class="comment-label" style="color: #ff0000;">Мой комментарий:</p>
  <p class="comment-text">1 лекция Машинное обучение. Вводная лекция. К.В. Воронцов, Школа анализа данных, Яндекс.  https://www.youtube.com/watch?v=SZkrxWhI5qM&list=PLJOzdkh8T5krxc4HsHbB8g8f0hu7973fK</p>
</div>

## §1.1 Основные понятия и определения
([4](zotero://open-pdf/library/items/BHYQ63Y9?page=4&annotation=SZRMSAPB))

###### целевая функция (target function) y∗ : X → Y
([4](zotero://open-pdf/library/items/BHYQ63Y9?page=4&annotation=E724HWG2))
<div class="custom-comment" style="border-left: 4px solid #ffff00; background-color: #fffff0;">
  <p class="comment-label" style="color: #ffff00;">Мой комментарий:</p>
  <p class="comment-text">неизвестная зависимость</p>
</div>

###### {x1, . . . , xl} ⊂ X
([4](zotero://open-pdf/library/items/BHYQ63Y9?page=4&annotation=395ARFKT))
<div class="custom-comment" style="border-left: 4px solid #ffff00; background-color: #fffff0;">
  <p class="comment-label" style="color: #ffff00;">Мой комментарий:</p>
  <p class="comment-text">известны ответы на конечном множестве объектов</p>
</div>

##### Задача обучения по прецедентам заключается в том, чтобы по выборке Xl восстановить зависимость y∗, то есть построить решающую функцию (decision function) a : X → Y , которая приближала бы целевую функцию y∗(x), причём не только на объектах обучающей выборки, но и на всём множестве X.
([4](zotero://open-pdf/library/items/BHYQ63Y9?page=4&annotation=724RESVM))
<div class="custom-comment" style="border-left: 4px solid #008000; background-color: #f0fff0;">
  <p class="comment-label" style="color: #008000;">Мой комментарий:</p>
  <p class="comment-text">задача обучения с учителем</p>
</div>

### 1.1.1 Объекты и признаки
([4](zotero://open-pdf/library/items/BHYQ63Y9?page=4&annotation=5CIRADKZ))

##### Признак (feature) f объекта x это результат измерения некоторой характеристики объекта. Формально признаком называется отображение f : X → Df , где Df множество допустимых значений признака. В частности, любой алгоритм a : X → Y также можно рассматривать как признак.
([4](zotero://open-pdf/library/items/BHYQ63Y9?page=4&annotation=98BNK5G5))
<div class="custom-comment" style="border-left: 4px solid #008000; background-color: #f0fff0;">
  <p class="comment-label" style="color: #008000;">Мой комментарий:</p>
  <p class="comment-text">например объект - это пациент, а у пациента мы можем измерить температуру и тд - это будет его признак. Получается D_f - множество возможных температур (35,36,37), а объект X имеет свое отображение в конкретной температуре</p>
</div>

###### Если все признаки имеют одинаковый тип, Df1 = · · · = Dfn, то исходные данные  называются однородными, в противном случае разнородными.
([4](zotero://open-pdf/library/items/BHYQ63Y9?page=4&annotation=REZ7APCV))
<div class="custom-comment" style="border-left: 4px solid #ffff00; background-color: #fffff0;">
  <p class="comment-label" style="color: #ffff00;">Мой комментарий:</p>
  <p class="comment-text">хз что это такое и где применяется</p>
</div>

![[_attachments/k.v.voroncovMatematicheskieOsnovyMashinnogo/image-4-x95-y123.png]]
<div class="custom-comment" style="border-left: 4px solid #ffff00; background-color: #fffff0;">
  <p class="comment-label" style="color: #ffff00;">Мой комментарий:</p>
  <p class="comment-text">Пусть имеется набор признаков f1, . . . , fn. Вектор (f1(x), . . . , fn(x)) называют  признаковым описанием объекта x ∈ X. В дальнейшем мы не будем различать объекты из X и их признаковые описания, полагая X = Df1 × . . . × Dfn. Совокупность признаковых описаний всех объектов выборки Xl, записанную в виде таблицы размера l × n, называют матрицей объектов–признаков:</p>
</div>

### 1.1.2 Ответы и типы задач
([5](zotero://open-pdf/library/items/BHYQ63Y9?page=5&annotation=J5GDZGMZ))

##### Если Y = {1, . . . , M }, то это задача классификации (classification) на M непересекающихся классов.
([5](zotero://open-pdf/library/items/BHYQ63Y9?page=5&annotation=4IKB5ZAM))
<div class="custom-comment" style="border-left: 4px solid #008000; background-color: #f0fff0;">
  <p class="comment-label" style="color: #008000;">Мой комментарий:</p>
  <p class="comment-text">например {0, 1} - бинарная классификация</p>
</div>

Если Y = {0, 1}M , то это задача классификации на M пересекающихся классов. В простейшем случае эта задача сводится к решению M независимых задач классификации с двумя непересекающимися классами.
Давайте разберем это утверждение по частям, чтобы полностью понять его смысл в контексте машинного обучения.

### Y = {0, 1}M: Что это значит?

*   **Y** в контексте машинного обучения обычно обозначает вектор целевых значений или меток (labels) для одного экземпляра данных.
*   **M** — это количество возможных классов или категорий.
*   **{0, 1}** означает, что каждое значение в векторе Y может быть либо 0 (класс отсутствует), либо 1 (класс присутствует).
*   **{0, 1}M** означает, что Y представляет собой вектор из M элементов, где каждый элемент является либо 0, либо 1. Например, если M=3, Y может быть (1, 0, 1), (0, 1, 0), (1, 1, 0) и так далее.

Таким образом, если $Y = \{0, 1\}^M$, это означает, что для каждого объекта мы имеем $M$ бинарных меток, каждая из которых указывает на присутствие (1) или отсутствие (0) соответствующего класса.

### "Это задача классификации на M пересекающихся классов"

Эта формулировка указывает на **многометочную (multi-label) классификацию**.

*   **Многометочная классификация** отличается от **многоклассовой (multi-class) классификации** (где каждый объект принадлежит *только к одному* из $M$ непересекающихся классов).
*   В многометочной классификации один объект может одновременно принадлежать к *нескольким* классам. Например, фотография может содержать "собаку" (класс 1), "кошку" (класс 0) и "траву" (класс 1) — вектор меток (1, 0, 1).
*   **"Пересекающиеся классы"** здесь означает, что категории не являются взаимоисключающими. Присутствие одного класса (например, "текст о политике") не исключает присутствия другого класса ("текст об экономике") в том же документе. Объект может быть одновременно помечен несколькими метками.

### "В простейшем случае эта задача сводится к решению M независимых задач классификации с двумя непересекающимися классами."

Это описывает один из наиболее распространенных и простых подходов к решению задач многометочной классификации, известный как **"бинарная релевантность" (Binary Relevance)**.

*   **"M независимых задач классификации"**: Вместо того чтобы пытаться предсказать весь вектор $Y$ за один раз, мы создаем $M$ отдельных, независимых классификаторов.
*   **"С двумя непересекающимися классами"**: Каждый из этих $M$ классификаторов является бинарным. Для $j$-го класса он отвечает на вопрос: "Присутствует ли класс $j$ в данном объекте (1) или нет (0)?" Эти два состояния ("присутствует" или "отсутствует") являются взаимоисключающими *для данного конкретного класса*.
    *   Например, для первой метки мы обучаем классификатор, который отличает объекты с меткой 1 от объектов без метки 1.
    *   Для второй метки мы обучаем отдельный классификатор, который отличает объекты с меткой 2 от объектов без метки 2, и так далее.
*   **"Независимых"** подразумевает, что модель не учитывает потенциальные корреляции между метками. Например, если мы знаем, что "фильм является романтическим", то, вероятно, он также является "комедией" (если это "романтическая комедия"). Простейший подход с бинарной релевантностью не использует эту информацию, рассматривая предсказание каждой метки как отдельную, несвязанную задачу.

**Пример:**

Предположим, у нас есть задача классификации фильмов по жанрам, и M=3 возможных жанра: {Боевик, Комедия, Драма}.
Для фильма "Мальчишник в Вегасе" метки могут быть: (0, 1, 0) – не боевик, комедия, не драма.
Для фильма "Железный человек" метки могут быть: (1, 0, 0) – боевик, не комедия, не драма.
Для фильма "Дэдпул" метки могут быть: (1, 1, 0) – боевик, комедия, не драма.

Это задача классификации на 3 пересекающихся класса (Боевик и Комедия могут быть одновременно).

В простейшем случае мы можем решить её так:
1.  **Классификатор 1 (для жанра "Боевик")**: Для каждого фильма предсказываем, является ли он боевиком (1) или нет (0).
2.  **Классификатор 2 (для жанра "Комедия")**: Для каждого фильма предсказываем, является ли он комедией (1) или нет (0).
3.  **Классификатор 3 (для жанра "Драма")**: Для каждого фильма предсказываем, является ли он драмой (1) или нет (0).

Каждый из этих 3 классификаторов работает независимо и является задачей бинарной классификации.

Задачи прогнозирования (forecasting) являются частными случаями классификации или восстановления регрессии, когда x ∈ X описание прошлого поведения объекта x, y ∈ Y описание некоторых характеристик его будущего поведения.
** вопрос если я предсказываю глюкозу, но при этом люди разделены на когорты по возрасту, то головка (которая предсказыввает) выполняет щадачу регрессии, а енкодер, который запомнинает массивы по 188 значений (а потом мы уменьшаем его размерность чтобы увидеть что он увидел признаки когорт) то он выполняет задачу классификации? **


1.  **Головка (Prediction Head), которая предсказывает глюкозу:**
    *   **Задача: Регрессия.** Вы совершенно правы. Поскольку глюкоза — это непрерывное числовое значение (например, 5.5 ммоль/л, 8.2 ммоль/л), предсказание такого значения является задачей регрессии. Головка берет выходные данные энкодера (скрытое представление) и преобразует их в конечное предсказанное значение глюкозы.

2.  **Энкодер (Encoder), который обрабатывает массивы по 188 значений:**
    *   **Задача: Извлечение признаков (Feature Extraction) / Обучение представлений (Representation Learning).** Это основная задача энкодера. Он берет "сырые" входные данные (массивы по 188 значений, которые, вероятно, являются временными рядами данных НМГ или другими биометрическими показателями) и преобразует их в более компактное, высокоуровневое и информативное скрытое представление (так называемый "эмбеддинг" или "вектор признаков").
    *   **Отношение к когортам по возрасту:**
        *   **Непрямая классификация (если цель - только предсказание глюкозы):** Если ваша *единственная* обучающая задача — предсказание глюкозы, то энкодер будет учиться извлекать те признаки из 188 значений, которые наиболее полезны для точного предсказания глюкозы. Если паттерны глюкозы *отличаются* в разных возрастных когортах, то энкодер *может* неявно научиться кодировать информацию о когорте, потому что это помогает ему лучше предсказывать глюкозу. В этом случае энкодер *сам по себе не выполняет* задачу классификации когорт. Он просто формирует такое представление данных, которое *позволяет* головке регрессии быть точнее.
        *   **Визуализация после снижения размерности:** Когда вы "уменьшаете его размерность, чтобы увидеть, что он увидел признаки когорт" (например, с помощью PCA, t-SNE), вы фактически выполняете **классификацию/кластеризацию или визуальный анализ *на выходе энкодера***. Это не означает, что сам энкодер выполнял задачу классификации. Это лишь показывает, что энкодер *успешно извлек* признаки, которые коррелируют с возрастными когортами, даже если его прямая цель была регрессия.

**Однако, есть сценарий, когда энкодер может быть задействован в классификации:**

*   **Многозадачное обучение (Multi-task Learning):** Если вы специально разработали модель таким образом, чтобы она решала *две задачи одновременно*:
    1.  Предсказание глюкозы (регрессия).
    2.  Определение возрастной когорты (классификация).
    В этом случае у вас будет энкодер, который генерирует общее скрытое представление, а затем **две отдельные головки (или ветви)**, отходящие от этого энкодера:
        *   Одна головка выполняет **регрессию** для предсказания глюкозы.
        *   Вторая головка выполняет **классификацию** (например, многоклассовую классификацию) для предсказания возрастной когорты.
    В таком сценарии энкодер обучается извлекать признаки, полезные для *обеих* задач, и его обучающая задача включает компоненты как регрессии, так и классификации.

**Итого:**

*   **Головка (выходная часть):** Выполняет **регрессию** для предсказания непрерывного значения глюкозы.
*   **Энкодер (внутренняя часть):** Выполняет **извлечение признаков / обучение представлений**. Он *может неявно* изучать характеристики когорт, если это помогает ему в основной задаче. Если вы затем используете его выход для *визуализации или кластеризации когорт*, то **этот дополнительный шаг** является задачей классификации/кластеризации, а не сам энкодер напрямую. Если же энкодер обучен в многозадачном режиме с отдельной классификационной головкой для когорт, то он *участвует* в классификации как часть своей обучающей цели.

В вашем вопросе, формулировка "чтобы увидеть, что он увидел признаки когорт" скорее указывает на то, что энкодер *неявно* выучил эти признаки, а не *напрямую* выполнял классификационную задачу для когорт.

### 1.1.3 Модель алгоритмов и метод обучения
([5](zotero://open-pdf/library/items/BHYQ63Y9?page=5&annotation=SBW9JVDU))

Моделью алгоритмов называется параметрическое семейство отображений A = {g(x, θ) | θ ∈ Θ}, где g : X × Θ → Y некоторая фиксированная функция, Θ множество допустимых значений параметра θ, называемое пространством параметров или пространством поиска (search space).
Давайте переведем это по частям: <b>g(x, θ)</b> — это <b>"модель-предсказатель"</b>. Это функция, которая по объекту x (например, данным о квартире) и параметру θ выдает прогноз y. <b><br/></b>

g — это фиксированная формула. Мы ее выбираем заранее. <b><br/></b>


<b>θ (тета)</b> — это <b>параметр</b> (или вектор параметров) модели. Это "крутилки", которые мы будем настраивать в нашей формуле, чтобы модель лучше предсказывала. В примере с квартирой — это цена за квадратный метр. <b><br/></b>


<b>Θ (Тета)`</b> — это <b>пространство параметров</b>.Множество всех возможных значений, которые может принимать наш параметр θ. Например, "цена за кв.м. не может быть отрицательной", значит Θ = (0, +∞). <b><br/></b>


<b>A = {g(x, θ) | θ ∈ Θ}</b> — это <b>"параметрическое семейство отображений"</b>.Это ключевая мысль! <b>Модель — это не одна функция, а целое семейство!</b>Каждому возможному значению параметра θ из пространства Θ соответствует своя конкретная функция-предсказатель g(x, θ). <b><br/></b>


<b>Обучение модели</b> — это процесс поиска в пространстве Θ такого значения параметра θ*, при котором наша функция g(x, θ*) предсказывает <b>наилучшим образом</b>. <b><br/></b>


<b>Аналогия: </b><b><br/></b>
Представьте, что g(x, θ) — это формула прямой линии y = k*x + b. <b><br/></b>
x — это входное число.  <b><br/></b>
θ = (k, b) — это параметры (угловой коэффициент и сдвиг). <b><br/></b>

Θ = R² — пространство параметров (любые возможные пары чисел k и b). <b><br/></b>
<b>Модель A</b> — это не одна прямая, а <b>семейство всех возможных прямых на плоскости</b>. Задача алгоритма обучения — найти ту единственную прямую (k* и b*), которая лучше всего аппроксимирует наши данные.

![[_attachments/k.v.voroncovMatematicheskieOsnovyMashinnogo/image-5-x95-y316.png]]
<div class="custom-comment" style="border-left: 4px solid #ffff00; background-color: #fffff0;">
  <p class="comment-label" style="color: #ffff00;">Мой комментарий:</p>
  <p class="comment-text">Что происходит? Мы решаем задачу прогнозирования числа. <b><br/></b>
Например, прогноз цены акций, температуры, спроса.<b>f_j(x) — это признаки (features)</b>. Это не сырые данные, а какие-то измеримые характеристики объекта x. <b><br/></b>

Пример для квартиры: x — это квартира. Тогда f₁(x) — площадь, f₂(x) — количество комнат, f₃(x) — этаж, f₄(x) — расстояние до метро. <b><br/></b>


θ_j — это веса признаков. Параметры, которые мы обучаем. <b><br/></b>

θ₁ — вес площади (цена за кв.м.), θ₂ — "цена" за дополнительную комнату, θ₃ — "цена" за этаж и т.д. <b><br/></b>


Сама модель g: Это <b>взвешенная сумма признаков</b>. Каждый признак вносит свой вклад в итоговый прогноз, пропорционально своему весу θ_j. <b><br/></b>

Для квартиры: Прогноз_цены = (θ₁ * Площадь) + (θ₂ * Комнаты) + (θ₃ * Этаж) + ...</p>
</div>

![[_attachments/k.v.voroncovMatematicheskieOsnovyMashinnogo/image-5-x96-y274.png]]
<div class="custom-comment" style="border-left: 4px solid #ffff00; background-color: #fffff0;">
  <p class="comment-label" style="color: #ffff00;">Мой комментарий:</p>
  <p class="comment-text"><b>Что происходит?</b> Мы решаем задачу классификации на два класса. <b><br/></b>
Например, отнести email к "спму" (+1) или "не спаму" (-1). <b><br/></b>
<b>Внутренняя часть ∑ θ_j * f_j(x)</b> — это точно такая же линейная комбинация, как и в регрессии. Ее часто называют <b>"решающей функцией"</b>. <b><br/></b>
Она выдает какое-то число. Если это число большое и положительное — у объекта много признаков класса +1. Если большое и отрицательное — класса -1. <b><br/></b>
<b>Функция sign()</b> — это "проявитель". Она берет результат решающей функции и превращает его в чистый ответ класса:sign(z) = +1, если z >= 0 <b><br/></b>
sign(z) = -1, если z < 0 <b><br/></b>
<b>Проще говоря:</b> Сначала мы вычисляем "уверенность" модели в том, что объект принадлежит классу +1. Если уверенность положительная — ставим +1, если отрицательная — ставим -1.</p>
</div>

##### полином
([5](zotero://open-pdf/library/items/BHYQ63Y9?page=5&annotation=DLNSF42E))
<div class="custom-comment" style="border-left: 4px solid #008000; background-color: #f0fff0;">
  <p class="comment-label" style="color: #008000;">Мой комментарий:</p>
  <p class="comment-text">Полином (или <b>многочлен</b>) — это математическое выражение, которое представляет собой сумму нескольких слагаемых, где каждое слагаемое — это число, умноженное на переменную в натуральной степени. <b><br/></b>
Проще говоря, это комбинация из нескольких "одночленов", сложенных или вычтенных друг из друга. <b><br/></b>

<b>3x² + x - 5</b> (полином второй степени, или квадратный) <b><br/></b>
<b>x - 7</b> (полином первой степени, или линейный) <b><br/></b>
<b>4</b> (полином нулевой степени, это просто число)</p>
</div>

### 1.1.4 Функционал качества
([6](zotero://open-pdf/library/items/BHYQ63Y9?page=6&annotation=A7VR38JV))

##### Функция потерь (loss function)
([6](zotero://open-pdf/library/items/BHYQ63Y9?page=6&annotation=JLL9RC6T))
<div class="custom-comment" style="border-left: 4px solid #008000; background-color: #f0fff0;">
  <p class="comment-label" style="color: #008000;">Мой комментарий:</p>
  <p class="comment-text">это неотрицательная функция L (a, x), характеризующая величину ошибки алгоритма a на объекте x. Если L (a, x) = 0, то ответ a(x) называется корректным.</p>
</div>

##### Функционал качества алгоритма a на выборке Xl
([6](zotero://open-pdf/library/items/BHYQ63Y9?page=6&annotation=HQAWTRQ8))

![[_attachments/k.v.voroncovMatematicheskieOsnovyMashinnogo/image-6-x97-y434.png]]

###### эмпирическим данным
([6](zotero://open-pdf/library/items/BHYQ63Y9?page=6&annotation=N4AFGH8X))
<div class="custom-comment" style="border-left: 4px solid #ffff00; background-color: #fffff0;">
  <p class="comment-label" style="color: #ffff00;">Мой комментарий:</p>
  <p class="comment-text">Слово "эмпирический" происходит от греческого empeiria — "опыт". То есть, это данные, которые были получены в результате наблюдений, измерений или экспериментов в реальном мире, а не выведены теоретически.</p>
</div>

![[_attachments/k.v.voroncovMatematicheskieOsnovyMashinnogo/image-6-x96-y154.png]]
<div class="custom-comment" style="border-left: 4px solid #ffff00; background-color: #fffff0;">
  <p class="comment-label" style="color: #ffff00;">Мой комментарий:</p>
  <p class="comment-text">Классический метод обучения, называемый минимизацией эмпирического риска (empirical risk minimization, ERM), заключается в том, чтобы найти в заданной модели A алгоритм a, доставляющий минимальное значение функционалу качества Q на заданной обучающей выборке Xl</p>
</div>

### 1.1.5 Вероятностная постановка задачи обучения
([7](zotero://open-pdf/library/items/BHYQ63Y9?page=7&annotation=TLP6F3S6))
