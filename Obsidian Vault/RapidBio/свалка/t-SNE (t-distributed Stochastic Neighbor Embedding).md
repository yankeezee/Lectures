Давайте подробно разберем t-SNE (t-distributed Stochastic Neighbor Embedding) — один из самых популярных алгоритмов для визуализации многомерных данных.

## Что такое t-SNE?

t-SNE — это нелинейный алгоритм уменьшения размерности, предназначенный в первую очередь для визуализации. Он преобразует данные из высокомерного пространства в пространство с низкой размерностью (обычно 2D или 3D), сохраняя локальные структуры данных.

## Основная идея алгоритма

### 1. Сходства в высокомерном пространстве
Для каждой пары точек в исходном пространстве вычисляется вероятность того, что они являются "соседями":

$$p_j|i = exp(-||x_i - x_j||² / 2σ_i²) / ∑_{k≠i} exp(-||x_i - x_k||² / 2σ_i²)$$

где σ_i подбирается так, чтобы перплексия распределения P_i равнялась заданной перплексии.

### 2. Сходства в низкомерном пространстве
В пространстве сниженной размерности используется распределение Стьюдента (t-распределение):

$$q_ij = (1 + ||y_i - y_j||²)⁻¹ / ∑_{k≠l} (1 + ||y_k - y_l||²)⁻¹$$


### 3. Минимизация расхождения
Алгоритм минимизирует расхождение Кульбака-Лейблера между распределениями P и Q:

$$KL(P||Q) = ∑_{i≠j} p_ij log(p_ij / q_ij)
$$

## Подробное объяснение параметров

### Основные параметры:

**`n_components`** (по умолчанию=2)
- Размерность целевого пространства
- Обычно 2 или 3 для визуализации

**`perplexity`** (по умолчанию=30.0)
- **Важнейший параметр!** Условно определяет количество ближайших соседей
- Типичные значения: 5-50
- Меньшие значения: акцент на локальных структурах
- Большие значения: учет глобальной структуры
- Должно быть меньше количества образцов

**`learning_rate`** (по умолчанию='auto')
- Скорость обучения оптимизатора
- Типичный диапазон: 10-1000
- Слишком высокое: точки выглядят как "шар"
- Слишком низкое: точки сжаты в плотное облако
- 'auto': автоматический подбор based on размера данных

**`max_iter`** (по умолчанию=1000)
- Максимальное количество итераций оптимизации
- Минимум 250, обычно 1000 достаточно

### Дополнительные параметры:

**`early_exaggeration`** (по умолчанию=12.0)
- Усиливает кластеры на ранних итерациях
- Помогает лучше разделить естественные кластеры

**`init`** (по умолчанию='pca')
- Инициализация вложений:
  - 'pca': более стабильная (рекомендуется)
  - 'random': случайная инициализация

**`method`** (по умолчанию='barnes_hut')
- Алгоритм вычисления:
  - 'barnes_hut': быстрый, O(N log N)
  - 'exact': точный, O(N²) - для небольших datasets

## Практические рекомендации

### Предобработка данных:
```python
# Рекомендуется сначала уменьшить размерность PCA до ~50
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

# Для данных с большим количеством признаков
pca = PCA(n_components=50)
X_pca = pca.fit_transform(X)

tsne = TSNE(n_components=2, perplexity=30, random_state=42)
X_embedded = tsne.fit_transform(X_pca)
```

### Выбор перплексии:
```python
# Поэкспериментируйте с разными значениями
perplexities = [5, 30, 50, 100]

for perplexity in perplexities:
    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)
    embedding = tsne.fit_transform(X)
    # Визуализируйте и сравните результаты
```

## Особенности и ограничения

### Преимущества:
- Отлично сохраняет локальные структуры
- Хорошо разделяет кластеры
- Эффективен для визуализации

### Ограничения:
- Вычислительно сложный для больших datasets
- Результаты зависят от начальной инициализации
- Не сохраняет глобальную структуру
- Интерпретация масштаба осей затруднена

## Пример использования

```python
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.datasets import load_digits

# Загрузка данных
digits = load_digits()
X, y = digits.data, digits.target

# Применение t-SNE
tsne = TSNE(
    n_components=2,
    perplexity=30,
    learning_rate='auto',
    init='pca',
    random_state=42,
    n_iter=1000
)

X_embedded = tsne.fit_transform(X)

# Визуализация
plt.figure(figsize=(10, 8))
scatter = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=y, cmap='tab10')
plt.colorbar(scatter)
plt.title('t-SNE визуализация цифр')
plt.show()
```

## Важные замечания

1. **t-SNE для визуализации, а не для feature extraction** - не используйте выход t-SNE как признаки для моделей ML

2. **Разные запуски = разные результаты** - из-за невыпуклости функции стоимости

3. **Масштабирование** - рекомендуется масштабировать данные перед применением t-SNE

4. **Размер кластеров** - в t-SNE не сохраняются информаци о размерах кластеров

t-SNE остается одним из самых мощных инструментов для визуального исследования многомерных данных, особенно когда нужно понять кластерную структуру dataset'а.

1 + 